{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2490\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mweights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \n\u001b[1;32m   2484\u001b[0m \u001b[38;5;124;03m  Note: This will not track the weights of nested `tf.Modules` that are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;124;03m    A list of variables.\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2490\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dedup_weights(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_undeduplicated_weights\u001b[49m)\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2495\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_undeduplicated_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2495\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m   weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2497\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_tracked_trackables:\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/sequential.py:467\u001b[0m, in \u001b[0;36mSequential._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# When the graph has not been initialized, use the Model's implementation to\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# to check if the weights has been created.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2671\u001b[0m, in \u001b[0;36mModel._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2663\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuild\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2666\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m!=\u001b[39m Model \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2667\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt):\n\u001b[1;32m   2668\u001b[0m   \u001b[38;5;66;03m# For any model that has customized build() method but hasn't\u001b[39;00m\n\u001b[1;32m   2669\u001b[0m   \u001b[38;5;66;03m# been invoked yet, this will cover both sequential and subclass model.\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m   \u001b[38;5;66;03m# Also make sure to exclude Model class itself which has build() defined.\u001b[39;00m\n\u001b[0;32m-> 2671\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeights for model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m have not yet been created. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2672\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeights are created when the Model is first called on \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2673\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs or `build()` is called with an `input_shape`.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   2674\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_1 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2490\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mweights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \n\u001b[1;32m   2484\u001b[0m \u001b[38;5;124;03m  Note: This will not track the weights of nested `tf.Modules` that are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;124;03m    A list of variables.\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2490\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dedup_weights(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_undeduplicated_weights\u001b[49m)\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2495\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_undeduplicated_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2495\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m   weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2497\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_tracked_trackables:\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/sequential.py:467\u001b[0m, in \u001b[0;36mSequential._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# When the graph has not been initialized, use the Model's implementation to\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# to check if the weights has been created.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LearningJourney_DeepLearning/Keras_DeepDive/.pixi/envs/default/lib/python3.9/site-packages/keras/engine/training.py:2671\u001b[0m, in \u001b[0;36mModel._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2663\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuild\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2666\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m!=\u001b[39m Model \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2667\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt):\n\u001b[1;32m   2668\u001b[0m   \u001b[38;5;66;03m# For any model that has customized build() method but hasn't\u001b[39;00m\n\u001b[1;32m   2669\u001b[0m   \u001b[38;5;66;03m# been invoked yet, this will cover both sequential and subclass model.\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m   \u001b[38;5;66;03m# Also make sure to exclude Model class itself which has build() defined.\u001b[39;00m\n\u001b[0;32m-> 2671\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeights for model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m have not yet been created. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2672\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeights are created when the Model is first called on \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2673\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs or `build()` is called with an `input_shape`.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   2674\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential_1 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.23953831, -0.25388455, -0.24893025,  0.15530866, -0.170135  ,\n",
       "         -0.2443651 , -0.20262627,  0.05985314,  0.13533702, -0.2861918 ,\n",
       "          0.2078144 ,  0.03200617,  0.19123966,  0.2719429 , -0.05372162,\n",
       "         -0.29682022,  0.2659213 , -0.2556982 ,  0.24873418,  0.00649589,\n",
       "          0.09353334,  0.03125703, -0.24144891, -0.16454978,  0.22056818,\n",
       "          0.00096625, -0.21959847, -0.0608072 ,  0.08720025,  0.08692834,\n",
       "         -0.1614227 , -0.1761359 , -0.27643403, -0.05573997,  0.25408316,\n",
       "         -0.15616669,  0.03266436,  0.29695493,  0.14526922,  0.07995221,\n",
       "         -0.14997151,  0.12170151, -0.12521388, -0.25150833,  0.07163811,\n",
       "          0.08089429,  0.16244924,  0.20873463,  0.01433048, -0.09194414,\n",
       "          0.19782323,  0.10371754,  0.27166146, -0.09344909,  0.29198772,\n",
       "         -0.05721714, -0.2556374 , -0.21186984, -0.03821176, -0.19783679,\n",
       "          0.2703728 , -0.27226228,  0.07754695,  0.24739379],\n",
       "        [-0.16351889,  0.13264629,  0.07531077,  0.2705047 ,  0.14495865,\n",
       "         -0.24149242, -0.21449727,  0.14809957,  0.21295953,  0.17562306,\n",
       "          0.02288947, -0.09826817, -0.076684  , -0.01334077, -0.2423147 ,\n",
       "         -0.16645163,  0.2684945 ,  0.12664312,  0.11658213, -0.06589842,\n",
       "          0.15982881,  0.02540854,  0.18163022, -0.15424894, -0.04869092,\n",
       "          0.2163772 , -0.19702022, -0.13951626, -0.26606134,  0.19979027,\n",
       "          0.016884  ,  0.02227682,  0.06070367,  0.03149888,  0.02102771,\n",
       "         -0.11921556, -0.24221197,  0.11366367, -0.17388839, -0.15809941,\n",
       "         -0.18021819, -0.12728745,  0.16030711,  0.2807541 , -0.23565671,\n",
       "          0.22728086, -0.12840775, -0.12166107,  0.20926088, -0.2180082 ,\n",
       "          0.0895749 ,  0.14704186,  0.0344671 , -0.14234532,  0.00307342,\n",
       "          0.13608694, -0.15658006, -0.28293973,  0.10950369,  0.18348539,\n",
       "          0.18794554, -0.27305552, -0.11587022, -0.16527054],\n",
       "        [ 0.06383497, -0.03795713,  0.25117755,  0.06371903,  0.25816154,\n",
       "         -0.22530961,  0.03340971, -0.11912303,  0.18930757, -0.10499915,\n",
       "         -0.00743753,  0.10873213,  0.26007807,  0.1991877 ,  0.16633213,\n",
       "          0.12448898,  0.12754458,  0.00957826, -0.22863933,  0.23759925,\n",
       "         -0.0067111 , -0.20704025, -0.21327038,  0.2041977 , -0.01729947,\n",
       "         -0.00054836, -0.05135924, -0.26239473,  0.25580746, -0.20210607,\n",
       "         -0.13231067,  0.09473035, -0.27320015, -0.04925427, -0.05715886,\n",
       "          0.093896  ,  0.110488  ,  0.29654837,  0.08440778, -0.19601023,\n",
       "          0.01121098,  0.1957703 ,  0.07052764, -0.22321993, -0.20638964,\n",
       "         -0.15442502, -0.22246028, -0.25397116,  0.1971547 , -0.08820704,\n",
       "         -0.29884434,  0.15943381,  0.13832983, -0.03551355,  0.29273927,\n",
       "          0.22389126,  0.06908035, -0.24215147, -0.17105575,  0.22398162,\n",
       "         -0.13347663, -0.03276959,  0.05653378,  0.2764663 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.05759218, -0.18554741,  0.1561872 ,  0.07381788,  0.11246359,\n",
       "          0.18581149, -0.20464142, -0.1933592 ,  0.14181143,  0.22632638],\n",
       "        [ 0.00123748, -0.15615891, -0.16556698,  0.21200818, -0.03659879,\n",
       "         -0.17730764, -0.02084026,  0.03781223,  0.17888579,  0.05509382],\n",
       "        [ 0.20318955,  0.14238068,  0.14909166, -0.2212593 ,  0.05547988,\n",
       "         -0.06408028, -0.01072708,  0.01938584, -0.06286344, -0.06945907],\n",
       "        [-0.18504483, -0.20911407, -0.2575234 ,  0.15129814, -0.06187959,\n",
       "         -0.12035292,  0.20368376,  0.06206229,  0.2697554 , -0.11998335],\n",
       "        [-0.01031846,  0.16635653, -0.17943957, -0.12376305, -0.2738514 ,\n",
       "         -0.03706126,  0.13574153,  0.00842556, -0.2783109 ,  0.1306301 ],\n",
       "        [-0.26469553, -0.2036744 , -0.19238608, -0.23620711,  0.18652147,\n",
       "         -0.05620651, -0.21435104, -0.12780993,  0.27597108,  0.27792683],\n",
       "        [ 0.24602035, -0.1793412 ,  0.01844132, -0.22889343, -0.08408143,\n",
       "         -0.09912741,  0.06210417, -0.02661923,  0.16637167,  0.1339336 ],\n",
       "        [-0.00448489,  0.28451034, -0.133134  , -0.18068723, -0.08438712,\n",
       "          0.06948242,  0.0531587 ,  0.14825112,  0.16653663,  0.00128418],\n",
       "        [ 0.18100202,  0.24055043, -0.20027065,  0.20387346,  0.13671264,\n",
       "          0.14414126, -0.19843839,  0.02750933, -0.1462004 , -0.03091124],\n",
       "        [-0.12589267,  0.05981067, -0.14190383, -0.25295752,  0.0629352 ,\n",
       "          0.20325166, -0.1278766 , -0.03245586,  0.1323424 ,  0.08580309],\n",
       "        [ 0.03453171, -0.22315286, -0.07903965,  0.26567546, -0.04978013,\n",
       "         -0.14798364, -0.14910577,  0.10957077, -0.05234498,  0.16513026],\n",
       "        [ 0.04799703,  0.11456653, -0.01245433, -0.20371167,  0.28458557,\n",
       "          0.22894314, -0.24508822, -0.08597207,  0.14319372,  0.2582862 ],\n",
       "        [-0.03976391, -0.19130576, -0.24512646, -0.12248857, -0.19664612,\n",
       "         -0.10337231, -0.18804362, -0.13475396, -0.19460428,  0.14095238],\n",
       "        [-0.14753611, -0.12637855, -0.02604342, -0.16416222, -0.28309768,\n",
       "         -0.04493748, -0.07940875,  0.0963276 ,  0.20668724,  0.2468501 ],\n",
       "        [-0.09969896, -0.27541143, -0.00982177, -0.27111357,  0.1532377 ,\n",
       "          0.15532735, -0.27115417, -0.04822126, -0.16477078,  0.11180767],\n",
       "        [-0.0973555 ,  0.24892506,  0.11079311,  0.07148215, -0.2816376 ,\n",
       "          0.02154902,  0.23817423,  0.22403678, -0.22776952,  0.01555285],\n",
       "        [-0.0200257 , -0.16354036,  0.06748539,  0.08803651,  0.00987121,\n",
       "          0.15755525,  0.01337516,  0.1605744 ,  0.03686416,  0.09621361],\n",
       "        [ 0.25441483,  0.15005887,  0.22103032,  0.17631382, -0.05651119,\n",
       "          0.06945336, -0.05059189,  0.07307571,  0.13607013, -0.00437877],\n",
       "        [ 0.22887811, -0.1466503 ,  0.2305735 ,  0.17965668,  0.24783644,\n",
       "         -0.20418818,  0.2019217 ,  0.04043961,  0.26615384, -0.04484515],\n",
       "        [-0.15742885,  0.0936664 , -0.12980248,  0.17258081,  0.10920277,\n",
       "          0.22592595, -0.1800691 ,  0.2602286 ,  0.07469305,  0.26597992],\n",
       "        [-0.10716826, -0.24429882, -0.06075943,  0.2530515 ,  0.22471789,\n",
       "         -0.07239439,  0.27435574, -0.23158978,  0.13167086, -0.18653458],\n",
       "        [ 0.0681729 ,  0.12334445, -0.0520532 , -0.01375902, -0.16410145,\n",
       "         -0.2798602 ,  0.00703949, -0.12258831,  0.20195639, -0.22395368],\n",
       "        [ 0.22259817,  0.2338129 ,  0.27855006,  0.25728753, -0.00221032,\n",
       "         -0.18711863, -0.25479954, -0.15875953, -0.06222053, -0.14440629],\n",
       "        [ 0.11386001,  0.02403945,  0.2743484 ,  0.20013154, -0.01202098,\n",
       "         -0.18938681, -0.04765439,  0.0079892 ,  0.12300733,  0.1264571 ],\n",
       "        [ 0.17232126,  0.24867812,  0.14657617,  0.15512612,  0.17678788,\n",
       "          0.01215017, -0.20049441,  0.13529518,  0.02979693,  0.21580753],\n",
       "        [ 0.12428534, -0.0468495 , -0.15691085, -0.1055785 ,  0.08829394,\n",
       "          0.1033825 ,  0.22754231,  0.0745014 , -0.00987312, -0.23863971],\n",
       "        [ 0.02865264, -0.08188602,  0.21181205, -0.15182494, -0.14654045,\n",
       "         -0.23536529, -0.22096467, -0.10783704, -0.24747805, -0.02894783],\n",
       "        [-0.22829586,  0.13495702, -0.27406043, -0.20455459,  0.22027227,\n",
       "         -0.22665715,  0.10531372,  0.07096153, -0.18788368,  0.1791574 ],\n",
       "        [-0.06926654, -0.24393058, -0.06961888, -0.25331977, -0.04147561,\n",
       "          0.06175679, -0.14156759, -0.09079674, -0.19487557,  0.2102629 ],\n",
       "        [ 0.28372225, -0.13825446, -0.09189899, -0.25645882,  0.24397197,\n",
       "          0.02754992,  0.08049586,  0.2541581 ,  0.17063862,  0.19932061],\n",
       "        [ 0.11748049, -0.21810864,  0.15033057, -0.11278383,  0.21886727,\n",
       "         -0.01909137, -0.15884466,  0.05414948,  0.2303293 ,  0.11236   ],\n",
       "        [-0.0928013 , -0.17239505, -0.06908004, -0.21769914, -0.17804715,\n",
       "         -0.26695836, -0.21617685,  0.01106796,  0.11777967, -0.2586541 ],\n",
       "        [ 0.06253555, -0.07053375, -0.13828161, -0.10708164,  0.05848894,\n",
       "         -0.14024307, -0.21107614, -0.08733352, -0.28252125,  0.03457427],\n",
       "        [-0.0399965 , -0.05464487,  0.07154164,  0.07201666, -0.04836445,\n",
       "         -0.13132808, -0.21593565, -0.07015453, -0.10037223, -0.21434039],\n",
       "        [ 0.01207313, -0.17505503,  0.1539625 , -0.26202378, -0.10692589,\n",
       "          0.26268753,  0.10086   ,  0.01808199, -0.25819054, -0.26909795],\n",
       "        [-0.16528809,  0.28005484, -0.16192846, -0.11405669,  0.18218383,\n",
       "         -0.07691261,  0.13428411, -0.14626041,  0.23700848,  0.16262981],\n",
       "        [-0.24687506, -0.1146366 , -0.22455654,  0.06249726,  0.18200746,\n",
       "          0.27034518,  0.25123164, -0.0409179 ,  0.21666953,  0.13725328],\n",
       "        [ 0.14869294,  0.151602  ,  0.02414867,  0.02932623,  0.18238622,\n",
       "          0.06147531,  0.06583297, -0.11552709, -0.27159286,  0.26191363],\n",
       "        [ 0.15026641, -0.21729437, -0.20635968,  0.20458546,  0.16870502,\n",
       "         -0.04740979,  0.23412731,  0.12393904,  0.27662882,  0.17878282],\n",
       "        [ 0.03147173,  0.1601677 ,  0.09132287,  0.07233906, -0.19717762,\n",
       "          0.03019318, -0.25520396,  0.13428268,  0.23609182, -0.01261833],\n",
       "        [-0.22761223, -0.02272832,  0.04451895,  0.27534822,  0.24367759,\n",
       "         -0.16426358,  0.05152637,  0.2217783 ,  0.0509969 , -0.25199214],\n",
       "        [-0.2307028 , -0.05814801, -0.00592965,  0.25423715,  0.19549248,\n",
       "          0.07272312, -0.14763843,  0.09985662, -0.15669014,  0.11304331],\n",
       "        [-0.0077585 , -0.1862804 , -0.1957056 , -0.20094213,  0.16736612,\n",
       "         -0.27363816,  0.16583535, -0.2753888 , -0.1556549 ,  0.24214903],\n",
       "        [ 0.03306916, -0.02054778, -0.20018362,  0.05908215,  0.0523403 ,\n",
       "          0.26592526, -0.18390715, -0.21230623, -0.22089583,  0.14453554],\n",
       "        [ 0.05302075, -0.06262726, -0.08654186,  0.109824  , -0.14801161,\n",
       "          0.23489287,  0.2580599 , -0.14379182,  0.13307717,  0.26291576],\n",
       "        [-0.09052233,  0.21584716, -0.16942647,  0.03953302,  0.1533792 ,\n",
       "         -0.08085133, -0.11734232, -0.18036075,  0.07597038,  0.0942159 ],\n",
       "        [-0.24129431, -0.07876252,  0.11537293, -0.10220394, -0.03043854,\n",
       "          0.10399193, -0.23803367, -0.22803864, -0.20999318,  0.2147947 ],\n",
       "        [ 0.26004758,  0.11873874, -0.09567524, -0.22628364, -0.19741707,\n",
       "         -0.13412783, -0.20236686,  0.0356662 , -0.01013333, -0.02962089],\n",
       "        [-0.0250895 ,  0.04481283, -0.23970035,  0.08722475,  0.27591422,\n",
       "          0.10745347, -0.26907486, -0.2030074 , -0.11997838, -0.01447707],\n",
       "        [ 0.09399092,  0.195721  , -0.15640989, -0.01273715, -0.03633307,\n",
       "         -0.25150496,  0.26675817,  0.24487916,  0.22822782,  0.14550278],\n",
       "        [-0.06941243,  0.13708371, -0.20613858, -0.00921187, -0.21294662,\n",
       "          0.0541243 , -0.13376245, -0.18430313, -0.20898184,  0.16924086],\n",
       "        [-0.14397743,  0.18306008, -0.19425324,  0.23246256,  0.00855017,\n",
       "         -0.03146115,  0.05223778, -0.09978512, -0.2529878 , -0.28036562],\n",
       "        [ 0.11488697, -0.2633096 , -0.17911139,  0.13853335,  0.0535917 ,\n",
       "          0.00507653,  0.05878386, -0.2412929 ,  0.11680707,  0.2611235 ],\n",
       "        [-0.15959525,  0.05727217,  0.03453103, -0.03415477,  0.21360284,\n",
       "          0.20604795,  0.17328474,  0.01259574, -0.20085612,  0.24014428],\n",
       "        [-0.07608335,  0.2639825 , -0.00284794, -0.24869375, -0.05034423,\n",
       "         -0.20990655,  0.1868375 ,  0.28073034, -0.14868738, -0.15364511],\n",
       "        [-0.01386398, -0.06193133, -0.21013337,  0.01856962,  0.07555953,\n",
       "         -0.26066333,  0.06072122, -0.09908104,  0.27364096,  0.18426484],\n",
       "        [ 0.2040577 ,  0.23125449,  0.02044573,  0.15647474,  0.27161714,\n",
       "         -0.26474985, -0.24342331, -0.26346925, -0.07665518,  0.11806989],\n",
       "        [-0.00580317,  0.14855057, -0.23394132, -0.24934718, -0.17035139,\n",
       "         -0.07683481,  0.1476486 , -0.17928627,  0.04021075,  0.19405085],\n",
       "        [-0.20372158, -0.01427495,  0.22616932,  0.07288095, -0.13208151,\n",
       "         -0.26052925, -0.23691308,  0.01930743,  0.12211683, -0.2106213 ],\n",
       "        [ 0.27360132, -0.05197532, -0.26840132, -0.0970813 ,  0.07876611,\n",
       "         -0.10328297,  0.25158772,  0.07207322,  0.1883614 , -0.16011718],\n",
       "        [-0.10157827,  0.02272519, -0.08091502, -0.17106144, -0.01025885,\n",
       "         -0.10684402,  0.2803754 ,  0.1873874 , -0.24615823,  0.25714424],\n",
       "        [ 0.08871207, -0.1916634 , -0.00338706, -0.17950052,  0.12112382,\n",
       "          0.01666555,  0.1293701 ,  0.26876625,  0.18439242,  0.22889963],\n",
       "        [-0.22544283,  0.2782173 ,  0.02789453, -0.23582917,  0.15694132,\n",
       "          0.1706385 , -0.01199871, -0.10505976, -0.15344003,  0.0099549 ],\n",
       "        [ 0.20125118,  0.27388522,  0.2776601 , -0.22073704,  0.21110514,\n",
       "          0.1555722 ,  0.18790922, -0.12394364, -0.1543198 , -0.12547196]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\") # You can name a model\n",
    "model.add(layers.Dense(64, activation='relu', name='my_first_layer')) # You can name to layers\n",
    "model.add(layers.Dense(10, activation='softmax', name='my_last_layer'))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'my_input')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'dense_5')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = layers.Dense(64, activation='relu')(inputs)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_6')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = layers.Dense(10, activation='softmax')(features)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x30a8e9850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_depaertments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name='title')\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name='text_body')\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation='relu')(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority = layers.Dense(1, activation='sigmoid', name='priority')(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "department = layers.Dense(num_depaertments, activation='softmax', name='department')(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_body (InputLayer)          [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tags (InputLayer)               [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20100)        0           title[0][0]                      \n",
      "                                                                 text_body[0][0]                  \n",
      "                                                                 tags[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           1286464     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            65          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            260         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,286,789\n",
      "Trainable params: 1,286,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_depaertments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name='title')\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation='relu')(features)\n",
    "\n",
    "priority = layers.Dense(1, activation='sigmoid', name='priority')(features)\n",
    "department = layers.Dense(num_depaertments, activation='softmax', name='department')(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 07:35:59.966773: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2025-06-04 07:35:59.967291: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 29.9375 - priority_loss: 0.3141 - department_loss: 29.6234 - priority_mean_absolute_error: 0.4833 - department_accuracy: 0.3187\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.0429 - priority_loss: 0.3221 - department_loss: 33.7208 - priority_mean_absolute_error: 0.4908 - department_accuracy: 0.2406\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_depaertments))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "              metrics=[['mean_absolute_error'], ['accuracy']])\n",
    "model.fit([title_data, text_body_data, tags_data], [priority_data, department_data], epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data], [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5649088e-09],\n",
       "       [7.2121270e-10],\n",
       "       [9.2494512e-10],\n",
       "       ...,\n",
       "       [7.4242656e-10],\n",
       "       [1.6896542e-09],\n",
       "       [2.8754543e-09]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01033845e-16, 9.96505737e-01, 3.49424616e-03, 8.93376172e-12],\n",
       "       [9.52503108e-17, 9.94877517e-01, 5.12247486e-03, 1.30098250e-11],\n",
       "       [1.46907714e-16, 9.96526062e-01, 3.47390282e-03, 1.38067942e-11],\n",
       "       ...,\n",
       "       [1.54934886e-16, 9.98512924e-01, 1.48706837e-03, 1.67434885e-11],\n",
       "       [3.75453343e-17, 9.99086261e-01, 9.13777505e-04, 4.83453902e-12],\n",
       "       [3.58023119e-16, 9.98398244e-01, 1.60174503e-03, 6.26006798e-12]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49186874],\n",
       "       [0.26243433],\n",
       "       [0.78481713],\n",
       "       ...,\n",
       "       [0.06719329],\n",
       "       [0.31714829],\n",
       "       [0.28875229]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 40.7185 - priority_loss: 0.3308 - department_loss: 40.3876 - priority_mean_absolute_error: 0.4988 - department_accuracy: 0.2680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x310be1910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"}, metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, {\"priority\": priority_data, \"department\": department_data}, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 54.0573 - priority_loss: 0.3226 - department_loss: 53.7347 - priority_mean_absolute_error: 0.4913 - department_accuracy: 0.2750\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 43.8552 - priority_loss: 0.3221 - department_loss: 43.5331 - priority_mean_absolute_error: 0.4908 - department_accuracy: 0.1266\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"}, metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, {\"priority\": priority_data, \"department\": department_data}, epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x30a8eb0a0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x30a9056a0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x30a905fd0>,\n",
       " <keras.layers.merge.Concatenate at 0x30a8fd070>,\n",
       " <keras.layers.core.Dense at 0x30a8fd670>,\n",
       " <keras.layers.core.Dense at 0x30a8f57c0>,\n",
       " <keras.layers.core.Dense at 0x30a8f0ee0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate_2')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "\n",
    "difficulty = layers.Dense(3, activation='softmax', name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(new_model, \"updated_ticket_classfier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 24.1386 - output_1_loss: 0.3167 - output_2_loss: 23.8219 - output_1_mean_absolute_error: 0.4857 - output_2_accuracy: 0.2211\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 18.8641 - output_1_loss: 0.3221 - output_2_loss: 18.5421 - output_1_mean_absolute_error: 0.4908 - output_2_accuracy: 0.5695\n"
     ]
    }
   ],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self, num_depaertments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_layer = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")\n",
    "        self.department_layer = layers.Dense(num_depaertments, activation=\"softmax\", name=\"department\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "        \n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_layer(features)\n",
    "        department = self.department_layer(features)\n",
    "        \n",
    "        return priority, department\n",
    "\n",
    "model = CustomerTicketModel(num_depaertments=4)\n",
    "priority, department = model({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"], \n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data], \n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, [priority_data, department_data])\n",
    "priority, department_data = model.predict({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classfier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classfier\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2967 - accuracy: 0.9112 - val_loss: 0.1559 - val_accuracy: 0.9564\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1652 - accuracy: 0.9538 - val_loss: 0.1267 - val_accuracy: 0.9666\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1397 - accuracy: 0.9631 - val_loss: 0.1148 - val_accuracy: 0.9710\n",
      "313/313 [==============================] - 0s 623us/step - loss: 0.1109 - accuracy: 0.9715\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2973 - accuracy: 0.9120 - rmse: 7.1832 - val_loss: 0.1484 - val_accuracy: 0.9588 - val_rmse: 7.3530\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1638 - accuracy: 0.9544 - rmse: 7.3534 - val_loss: 0.1192 - val_accuracy: 0.9686 - val_rmse: 7.4035\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1399 - accuracy: 0.9627 - rmse: 7.3885 - val_loss: 0.1133 - val_accuracy: 0.9706 - val_rmse: 7.4195\n",
      "313/313 [==============================] - 0s 927us/step - loss: 0.1030 - accuracy: 0.9724 - rmse: 7.4344\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2990 - accuracy: 0.9111 - val_loss: 0.1490 - val_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1673 - accuracy: 0.9528 - val_loss: 0.1194 - val_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1397 - accuracy: 0.9626 - val_loss: 0.1216 - val_accuracy: 0.9686\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1287 - accuracy: 0.9667 - val_loss: 0.1058 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1195 - accuracy: 0.9696 - val_loss: 0.1042 - val_accuracy: 0.9752\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1092 - accuracy: 0.9731 - val_loss: 0.1046 - val_accuracy: 0.9769\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1018 - accuracy: 0.9747 - val_loss: 0.1113 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0992 - accuracy: 0.9773 - val_loss: 0.1191 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1005 - accuracy: 0.9771 - val_loss: 0.1201 - val_accuracy: 0.9782\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9792 - val_loss: 0.1165 - val_accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3138ca640>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=callbacks_list, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses, label=\"Training Loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2980 - accuracy: 0.9107 - val_loss: 0.1507 - val_accuracy: 0.9574\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1649 - accuracy: 0.9546 - val_loss: 0.1361 - val_accuracy: 0.9641\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1381 - accuracy: 0.9626 - val_loss: 0.1078 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1264 - accuracy: 0.9668 - val_loss: 0.1137 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1184 - accuracy: 0.9701 - val_loss: 0.1113 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1088 - accuracy: 0.9730 - val_loss: 0.1106 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 0.1239 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1021 - accuracy: 0.9758 - val_loss: 0.1144 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0956 - accuracy: 0.9778 - val_loss: 0.1140 - val_accuracy: 0.9780\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0977 - accuracy: 0.9781 - val_loss: 0.1264 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30a819910>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, callbacks=[LossHistory()], validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1563 [..............................] - ETA: 3:17 - loss: 2.5042 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 07:39:15.068447: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2025-06-04 07:39:15.068466: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2025-06-04 07:39:15.068891: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2025-06-04 07:39:15.226820: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2025-06-04 07:39:15.226831: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2025-06-04 07:39:15.229136: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2025-06-04 07:39:15.235240: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2025-06-04 07:39:15.241235: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: train/plugins/profile/2025_06_04_07_39_15\n",
      "\n",
      "2025-06-04 07:39:15.241830: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.trace.json.gz\n",
      "2025-06-04 07:39:15.246690: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: train/plugins/profile/2025_06_04_07_39_15\n",
      "\n",
      "2025-06-04 07:39:15.247027: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.memory_profile.json.gz\n",
      "2025-06-04 07:39:15.247617: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: train/plugins/profile/2025_06_04_07_39_15\n",
      "Dumped tool data for xplane.pb to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to train/plugins/profile/2025_06_04_07_39_15/Yuhaos-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2961 - accuracy: 0.9116 - val_loss: 0.1602 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1698 - accuracy: 0.9523 - val_loss: 0.1305 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1434 - accuracy: 0.9626 - val_loss: 0.1199 - val_accuracy: 0.9694\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1242 - accuracy: 0.9674 - val_loss: 0.1160 - val_accuracy: 0.9705\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1185 - accuracy: 0.9700 - val_loss: 0.0987 - val_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9738 - val_loss: 0.1076 - val_accuracy: 0.9755\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1062 - accuracy: 0.9748 - val_loss: 0.1135 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1039 - accuracy: 0.9760 - val_loss: 0.1123 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0999 - accuracy: 0.9776 - val_loss: 0.1154 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0988 - accuracy: 0.9774 - val_loss: 0.1140 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x31177d310>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"\")\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c49b425537a1080\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c49b425537a1080\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result after updating state: 1.0\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"Result after updating state: {current_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.0\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    \n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    \n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    \n",
    "    return logs\n",
    "\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9134\n",
      "...loss: 0.2927\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9535\n",
      "...loss: 0.1662\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9627\n",
      "...loss: 0.1392\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3 \n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "...val_sparse_categorical_accuracy: 0.9646\n",
      "...val_loss: 0.1374\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Validation results\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.2974\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1679\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x33be36b80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.2976\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1648\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x33b9df850>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
