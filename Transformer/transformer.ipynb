{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "352a375f",
      "metadata": {
        "id": "352a375f"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "5527b6bf",
      "metadata": {
        "id": "5527b6bf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "import keras\n",
        "\n",
        "filename = keras.utils.get_file(\n",
        "    origin=(\n",
        "        \"https://storage.googleapis.com/download.tensorflow.org/\"\n",
        "        \"data/shakespeare.txt\"\n",
        "    ),\n",
        ")\n",
        "shakespeare = open(filename, \"r\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "4f024135",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4f024135",
        "outputId": "fe5e4255-1b0e-4659-d173-bf2f2de79e82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "shakespeare[:250]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "f20a4d25",
      "metadata": {
        "id": "f20a4d25"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sequence_length = 100\n",
        "\n",
        "def split_input(input, sequence_length):\n",
        "    for i in range(0, len(input), sequence_length):\n",
        "        yield input[i : i + sequence_length]\n",
        "\n",
        "features = list(split_input(shakespeare[:-1], sequence_length))\n",
        "labels = list(split_input(shakespeare[1:], sequence_length))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "d9409049",
      "metadata": {
        "id": "d9409049"
      },
      "outputs": [],
      "source": [
        "x, y = next(dataset.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "ca5d8c1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca5d8c1c",
        "outputId": "fc3dcbfe-8077-4d57-ed99-0f9deabca677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'First Citizen:\\nBefore we proceed any further, hear',\n",
              " b'irst Citizen:\\nBefore we proceed any further, hear ')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "x[:50], y[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "b64d1d66",
      "metadata": {
        "id": "b64d1d66"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "tokenizer = layers.TextVectorization(\n",
        "    standardize=None,\n",
        "    split=lambda x: tf.strings.unicode_split(x, 'UTF-8'),\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "tokenizer.adapt(dataset.map(lambda text, labels: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "66616c8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66616c8c",
        "outputId": "9574f0e9-2713-4805-d820-26a8d86490f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "vocabulary_size = tokenizer.vocabulary_size()\n",
        "vocabulary_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "f79058b2",
      "metadata": {
        "id": "f79058b2"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda features, labels: (tokenizer(features), tokenizer(labels)),\n",
        "    num_parallel_calls=8,\n",
        ")\n",
        "training_data = dataset.shuffle(10_000).batch(64).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "9f746349",
      "metadata": {
        "id": "9f746349"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "hidden_dim = 1024\n",
        "\n",
        "inputs = layers.Input(shape=(sequence_length,), dtype=tf.int32, name=\"token_ids\")\n",
        "x = layers.Embedding(vocabulary_size, embedding_dim)(inputs)\n",
        "x = layers.GRU(hidden_dim, return_sequences=True)(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(vocabulary_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs, name=\"shakespeare\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "3b18f398",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "3b18f398",
        "outputId": "21af7205-f78a-41d3-d28d-96fc60d6d081"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"shakespeare\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"shakespeare\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m17,152\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ gru_10 (\u001b[38;5;33mGRU\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m67\u001b[0m)          │        \u001b[38;5;34m68,675\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,152</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ gru_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,675</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,024,131\u001b[0m (15.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,024,131</span> (15.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,024,131\u001b[0m (15.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,024,131</span> (15.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "dcd98569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcd98569",
        "outputId": "e95bd3c3-5be0-45c3-a0e0-876d1ffa737f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.0603 - sparse_categorical_accuracy: 0.2360\n",
            "Epoch 2/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.9434 - sparse_categorical_accuracy: 0.4285\n",
            "Epoch 3/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.6696 - sparse_categorical_accuracy: 0.5024\n",
            "Epoch 4/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.5310 - sparse_categorical_accuracy: 0.5390\n",
            "Epoch 5/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.4484 - sparse_categorical_accuracy: 0.5602\n",
            "Epoch 6/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.3893 - sparse_categorical_accuracy: 0.5747\n",
            "Epoch 7/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.3430 - sparse_categorical_accuracy: 0.5863\n",
            "Epoch 8/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.3011 - sparse_categorical_accuracy: 0.5969\n",
            "Epoch 9/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.2627 - sparse_categorical_accuracy: 0.6069\n",
            "Epoch 10/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.2253 - sparse_categorical_accuracy: 0.6173\n",
            "Epoch 11/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1894 - sparse_categorical_accuracy: 0.6272\n",
            "Epoch 12/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1491 - sparse_categorical_accuracy: 0.6392\n",
            "Epoch 13/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1111 - sparse_categorical_accuracy: 0.6502\n",
            "Epoch 14/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.0784 - sparse_categorical_accuracy: 0.6593\n",
            "Epoch 15/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.0497 - sparse_categorical_accuracy: 0.6680\n",
            "Epoch 16/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.0163 - sparse_categorical_accuracy: 0.6775\n",
            "Epoch 17/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9898 - sparse_categorical_accuracy: 0.6852\n",
            "Epoch 18/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9727 - sparse_categorical_accuracy: 0.6904\n",
            "Epoch 19/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9597 - sparse_categorical_accuracy: 0.6942\n",
            "Epoch 20/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9458 - sparse_categorical_accuracy: 0.6980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e90bc35fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.fit(training_data, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "2ccac3eb",
      "metadata": {
        "id": "2ccac3eb"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"int\", name=\"token_ids\")\n",
        "input_state = keras.Input(shape=(hidden_dim,), name=\"state\")\n",
        "\n",
        "x = layers.Embedding(vocabulary_size, embedding_dim)(inputs)\n",
        "x, output_state = layers.GRU(hidden_dim, return_state=True)(\n",
        "    x, initial_state=input_state\n",
        ")\n",
        "outputs = layers.Dense(vocabulary_size, activation=\"softmax\")(x)\n",
        "generation_model = keras.Model(\n",
        "    inputs=(inputs, input_state),\n",
        "    outputs=(outputs, output_state),\n",
        ")\n",
        "generation_model.set_weights(model.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.get_vocabulary()\n",
        "token_ids = range(vocabulary_size)\n",
        "char_to_id = dict(zip(tokens, token_ids))\n",
        "id_to_char = dict(zip(token_ids, tokens))\n",
        "\n",
        "prompt = \"\"\"\n",
        "KING RICHARD III:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iBQb3-gI35mM"
      },
      "id": "iBQb3-gI35mM",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [char_to_id[c] for c in prompt]\n",
        "state = keras.ops.zeros(shape=(1, hidden_dim))\n",
        "for token_id in input_ids:\n",
        "    inputs = keras.ops.expand_dims([token_id], axis=0)\n",
        "    predictions, state = generation_model.predict((inputs, state), verbose=0)"
      ],
      "metadata": {
        "id": "YsdVcKb14TwN"
      },
      "id": "YsdVcKb14TwN",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "generated_ids = []\n",
        "max_length = 250\n",
        "for i in range(max_length):\n",
        "    next_char = int(np.argmax(predictions, axis=-1)[0])\n",
        "    generated_ids.append(next_char)\n",
        "    inputs = keras.ops.expand_dims([next_char], axis=0)\n",
        "    predictions, state = generation_model.predict((inputs, state), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "jPLJm7tG4wqt",
        "outputId": "61120ecc-53fd-4693-be2f-443bef35ee2f"
      },
      "id": "jPLJm7tG4wqt",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predictions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-95-2918375355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgenerated_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qcIB5TV-YlL"
      },
      "id": "1qcIB5TV-YlL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}