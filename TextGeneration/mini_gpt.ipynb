{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bc3cc09d",
      "metadata": {
        "id": "bc3cc09d"
      },
      "source": [
        "# MiniGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "64a5e7cd",
      "metadata": {
        "id": "64a5e7cd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e39831",
      "metadata": {
        "id": "11e39831"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pathlib\n",
        "\n",
        "extract_dir = keras.utils.get_file(\n",
        "    fname=\"mini-c4\",\n",
        "    origin=(\n",
        "        \"https://hf.co/datasets/mattdangerw/mini-c4/resolve/main/mini-c4.zip\"\n",
        "    ),\n",
        "    extract=True,\n",
        ")\n",
        "extract_dir = pathlib.Path(extract_dir) / \"mini-c4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be18ac0",
      "metadata": {
        "id": "4be18ac0"
      },
      "outputs": [],
      "source": [
        "with open(extract_dir / \"shard0.txt\", \"r\") as f:\n",
        "    print(f.readline().replace(\"\\\\n\", \"\\n\")[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7bab9d",
      "metadata": {
        "id": "3f7bab9d"
      },
      "outputs": [],
      "source": [
        "import keras_hub\n",
        "import numpy as np\n",
        "\n",
        "vocabulary_file = keras.utils.get_file(\n",
        "    origin=\"https://hf.co/mattdangerw/spiece/resolve/main/vocabulary.proto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_hub.tokenizers.SentencePieceTokenizer(vocabulary_file)"
      ],
      "metadata": {
        "id": "W2eo-KAbm1sZ"
      },
      "id": "W2eo-KAbm1sZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"The quick bron fox.\")"
      ],
      "metadata": {
        "id": "nAplF-GOm8Lw"
      },
      "id": "nAplF-GOm8Lw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.detokenize([450, 4996, 12246, 1701, 29916, 29889])"
      ],
      "metadata": {
        "id": "_-Adh49znAG-"
      },
      "id": "_-Adh49znAG-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 128\n",
        "sequence_length = 256\n",
        "suffix = np.array([tokenizer.token_to_id(\"<|endoftext|>\")])\n",
        "\n",
        "def read_file(filename):\n",
        "    ds = tf.data.TextLineDataset(filename)\n",
        "    ds = ds.map(lambda x: tf.strings.regex_replace(x, r\"\\\\n\", \"\\n\"))\n",
        "    ds = ds.map(tokenizer, num_parallel_calls=8)\n",
        "    return ds.map(lambda x: tf.concat([x, suffix], -1))\n",
        "\n",
        "files = [str(file) for file in extract_dir.glob(\"*.txt\")]\n",
        "ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "ds = ds.interleave(read_file, cycle_length=32, num_parallel_calls=32)\n",
        "ds = ds.rebatch(sequence_length + 1, drop_remainder=True)\n",
        "ds = ds.map(lambda x: (x[:-1], x[1:]))\n",
        "ds = ds.batch(batch_size).prefetch(8)"
      ],
      "metadata": {
        "id": "eG9BTFrEnIPn"
      },
      "id": "eG9BTFrEnIPn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = 29373\n",
        "num_val_batches = 500\n",
        "num_train_batches = num_batches - num_val_batches\n",
        "val_ds = ds.take(num_val_batches).repeat()\n",
        "train_ds = ds.skip(num_val_batches).repeat()"
      ],
      "metadata": {
        "id": "CK6VvjIwnmEd"
      },
      "id": "CK6VvjIwnmEd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "class TransformerDecoder(keras.Layer):\n",
        "    def __init__(self, hidden_dim, intermediate_dim, num_heads):\n",
        "        super().__init__()\n",
        "        key_dim = hidden_dim // num_heads\n",
        "        self.self_attention = layers.MultiHeadAttention(\n",
        "            num_heads, key_dim, dropout=0.1\n",
        "        )\n",
        "        self.self_attention_layernorm = layers.LayerNormalization()\n",
        "        self.feed_forward_1 = layers.Dense(intermediate_dim, activation=\"relu\")\n",
        "        self.feed_forward_2 = layers.Dense(hidden_dim)\n",
        "        self.feed_forward_layernorm = layers.LayerNormalization()\n",
        "        self.dropout = layers.Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        residual = x = inputs\n",
        "        x = self.self_attention(query=x, key=x, value=x, use_causal_mask=True)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "        x = self.self_attention_layernorm(x)\n",
        "        residual = x\n",
        "        x = self.feed_forward_1(x)\n",
        "        x = self.feed_forward_2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "        x = self.feed_forward_layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l4jHPawhnodw"
      },
      "id": "l4jHPawhnodw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import ops\n",
        "\n",
        "class PositionalEmbedding(keras.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = layers.Embedding(input_dim, output_dim)\n",
        "        self.position_embeddings = layers.Embedding(sequence_length, output_dim)\n",
        "\n",
        "    def call(self, inputs, reverse=False):\n",
        "        if reverse:\n",
        "            token_embeddings = self.token_embeddings.embeddings\n",
        "            return ops.matmul(inputs, ops.transpose(token_embeddings))\n",
        "        positions = ops.cumsum(ops.ones_like(inputs), axis=-1) - 1\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions"
      ],
      "metadata": {
        "id": "Gi78GZZJEN1q"
      },
      "id": "Gi78GZZJEN1q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.config.set_dtype_policy(\"mixed_float16\")\n",
        "\n",
        "vocab_size = tokenizer.vocabulary_size()\n",
        "hidden_dim = 512\n",
        "intermediate_dim = 2056\n",
        "num_heads = 8\n",
        "num_layers = 8\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"inputs\")\n",
        "embedding = PositionalEmbedding(sequence_length, vocab_size, hidden_dim)\n",
        "x = embedding(inputs)\n",
        "x = layers.LayerNormalization()(x)\n",
        "for i in range(num_layers):\n",
        "    x = TransformerDecoder(hidden_dim, intermediate_dim, num_heads)(x)\n",
        "outputs = embedding(x, reverse=True)\n",
        "mini_gpt = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "7wwka8aBG_Vx"
      },
      "id": "7wwka8aBG_Vx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmupSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self):\n",
        "        self.rate = 2e-4\n",
        "        self.warmup_steps = 1_000.0\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = ops.cast(step, dtype=\"float32\")\n",
        "        scale = ops.minimum(step / self.warmup_steps, 1.0)\n",
        "        return self.rate * scale"
      ],
      "metadata": {
        "id": "wAHNouIePcR-"
      },
      "id": "wAHNouIePcR-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "schedule = WarmupSchedule()\n",
        "x = range(0, 5_000, 100)\n",
        "y = [ops.convert_to_numpy(schedule(step)) for step in x]\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"Train Step\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZAGYhs6QFyf"
      },
      "id": "lZAGYhs6QFyf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "steps_per_epoch = num_train_batches // num_epochs\n",
        "validation_steps = num_val_batches\n",
        "\n",
        "mini_gpt.compile(\n",
        "    optimizer=keras.optimizers.Adam(schedule),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "mini_gpt.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "iQz3sHc-QZP5"
      },
      "id": "iQz3sHc-QZP5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, max_length=64):\n",
        "    tokens = list(ops.convert_to_numpy(tokenizer(prompt)))\n",
        "    prompt_length = len(tokens)\n",
        "    for _ in range(max_length - prompt_length):\n",
        "        prediction = mini_gpt(ops.convert_to_numpy([tokens]))\n",
        "        prediction = ops.convert_to_numpy(prediction[0, -1])\n",
        "        tokens.append(np.argmax(prediction).item())\n",
        "    return tokenizer.detokenize(tokens)"
      ],
      "metadata": {
        "id": "sS9WAqPPQfGd"
      },
      "id": "sS9WAqPPQfGd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A piece of advice\"\n",
        "generate(prompt)"
      ],
      "metadata": {
        "id": "p0HGLn14Trat"
      },
      "id": "p0HGLn14Trat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compiled_generate(prompt, max_length=64):\n",
        "    tokens = list(ops.convert_to_numpy(tokenizer(prompt)))\n",
        "    prompt_length = len(tokens)\n",
        "    tokens = tokens + [0] * (max_length - prompt_length)\n",
        "    for i in range(prompt_length, max_length):\n",
        "        prediction = mini_gpt.predict(np.array([tokens]), verbose=0)\n",
        "        prediction = prediction[0, i - 1]\n",
        "        tokens[i] = np.argmax(prediction).item()\n",
        "    return tokenizer.detokenize(tokens)"
      ],
      "metadata": {
        "id": "IWCLS1xuTu83"
      },
      "id": "IWCLS1xuTu83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "tries = 10\n",
        "timeit.timeit(lambda: compiled_generate(prompt), number=tries) / tries"
      ],
      "metadata": {
        "id": "eYoMcSU9YEPe"
      },
      "id": "eYoMcSU9YEPe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compiled_generate(prompt, sample_fn, max_length=64):\n",
        "    tokens = list(ops.convert_to_numpy(tokenizer(prompt)))\n",
        "    prompt_length = len(tokens)\n",
        "    tokens = tokens + [0] * (max_length - prompt_length)\n",
        "    for i in range(prompt_length, max_length):\n",
        "        prediction = mini_gpt.predict(np.array([tokens]), verbose=0)\n",
        "        prediction = prediction[0, i - 1]\n",
        "        next_token = ops.convert_to_numpy(sample_fn(prediction))\n",
        "        tokens[i] = np.array(next_token).item()\n",
        "    return tokenizer.detokenize(tokens)"
      ],
      "metadata": {
        "id": "OeAtSW_KYNxX"
      },
      "id": "OeAtSW_KYNxX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(preds):\n",
        "    return ops.argmax(preds)\n",
        "\n",
        "compiled_generate(prompt, greedy_search)"
      ],
      "metadata": {
        "id": "aw96hJMiYU-g"
      },
      "id": "aw96hJMiYU-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sample(preds, temperature=1.0):\n",
        "    preds = preds / temperature\n",
        "    return keras.random.categorical(preds[None, :], num_samples=1)[0]"
      ],
      "metadata": {
        "id": "IPoWLPRMYYYl"
      },
      "id": "IPoWLPRMYYYl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_generate(prompt, random_sample)"
      ],
      "metadata": {
        "id": "7kmvDj09YaJD"
      },
      "id": "7kmvDj09YaJD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "compiled_generate(prompt, partial(random_sample, temperature=2.0))\n",
        "compiled_generate(prompt, partial(random_sample, temperature=0.8))\n",
        "compiled_generate(prompt, partial(random_sample, temperature=0.2))"
      ],
      "metadata": {
        "id": "nbbNFVRjYbWP"
      },
      "id": "nbbNFVRjYbWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(preds, k=5, temperature=1.0):\n",
        "    preds = preds / temperature\n",
        "    top_preds, top_indices = ops.top_k(preds, k=k, sorted=False)\n",
        "    choice = keras.random.categorical(top_preds[None, :], num_samples=1)[0]\n",
        "    return ops.take_along_axis(top_indices, choice, axis=-1)"
      ],
      "metadata": {
        "id": "acKMw_oBYtkw"
      },
      "id": "acKMw_oBYtkw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_generate(prompt, partial(top_k, k=5))\n",
        "compiled_generate(prompt, partial(top_k, k=20))"
      ],
      "metadata": {
        "id": "djuN9z_FgGtx"
      },
      "id": "djuN9z_FgGtx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_generate(prompt, partial(top_k, k=5, temperature=0.5))"
      ],
      "metadata": {
        "id": "w1rb-1qYgKkO"
      },
      "id": "w1rb-1qYgKkO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}